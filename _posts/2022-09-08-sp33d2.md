---
published: false
---
## Need Another Hit

You ever stop in the middle of writing some code when it hits you? That nagging feeling. It's in the back of your mind, relentlessly gnawing away. Making you question your decisions. Making you wonder what you're doing with your life. You're plugging away happily, when suddenly you remember **I haven't optimized any code in *hours***.

It's no way to work.

It's no way to live.

Let's get back to our roots, blog.

## New Edition
For this edition of the blog, we're hopping off the usual tracks and onto a different set entirely: Vulkan driver optimization. I can already hear what you're thinking.

Vulkan drivers are already fast. Go back to doing something useful, like making GL work.

First: no they're not.

Second: I'm doing the opposite of that.

Third: shut up, it's my blog.

How does one optimize Vulkan drivers? As we all know, any great optimization needs a test case. And in the case of Vulkan, everyone who's anyone (me) uses Zink as their test case. The reasons for this are many and varied because I say they are, but the important one to keep in mind is, as always `drawoverhead`.

For those who can't remember the [times]({{site.url}}/hold-em) I have [previously]({{site.url}}/overhead) blogged [about]({{site.url}}/layin-that-pipe) the world's [premiere]({{site.url}}/description) benchmarking tool, don't worry. As with any great form of entertainment, I've prepared a recap.

## TL;DR drawoverhead
Suppose you are a large gaming-oriented company that sells hardware. Your hardware runs on a battery. The battery has a finite charge. Every bit of power drained from the battery powers the device so that users can play games.

Wouldn't it be great if that battery lasted longer?

There are a number of ways to achieve this goal. Because this is my blog, I'm going to talk about the one that doesn't involve underclocking or reducing graphical settings.

Obviously I'm talking about optimization, the process by which a smart and talented reader of StackOverflow copies and pastes code in exactly the right sequence such that, upon resolving all compilation errors, execution of a program utilizes fewer resources.

Now because everyone reading this is a GPU driver developer, we all know that optimization comes in two forms, optimizing for CPU and optimizing for GPU. But GPU optimization is easy. Anyone can do that. You just strap on your [RadeonGPUProfiler](https://gpuopen.com/rgp/) or [Nsight](https://developer.nvidia.com/nsight-graphics) or <insert Intel tool name here>, glance at the output, mumble mumble mumble, and blammo, your GPU is running like a clock. A really fast one though. With like a trillion hands all spinning at once.

So we're done with GPU optimization, but we're still not fast enough. The battery still doesn't last forever, and the users are still complaining on Reddit that they can't even finish a casual playthrough of Elden Ring without needing to plug in.

This brings us to "CPU optimization", the process by which we use more esoteric tools like [perf](http://www.brendangregg.com/perf.html) or [dtrace](http://dtrace.org/blogs/about/) or [custom instrumentation](({{site.url}}/sp33d2) to generate possibly-useful traces of where the CPU may or may not be spending time. But still, we need test cases, and unlike GPU profiling, CPU profiling typically isn't useful with only a single frame's worth of sample data.

Thus, `drawoverhead`, which provides a view of how various GL operations impact CPU utilization by executing millions of draw calls per second to provide copious samples for profiling.

## Why Not drawoverhead?
This is where the blog is going to take a turn for the bizarre. Some people, it seems, don't want to use Zink for benchmarking and profiling.
  
I know.
  
I'm shocked, hurt, appalled, and also it's me who doesn't want to use Zink for benchmarking and profiling so it's a very confusing time.
  
The problem with using Zink for optimizing CPU usage is that Zink keeps getting in the way. I want to profile only the Vulkan driver, but instead I've got all this Mesa oozing and spurting onto my CPU samples. It's gross, it's an untenable situation, and I've already taken steps to resolve it.
  
Behold the future: [vkoverhead](https://github.com/zmike/vkoverhead).
  
With one simple clone, build, and execute, it's now possible to see how much the Vulkan driver you're using sucks at any given task.
  
Want to see how costly it is to bind a different pipeline? Got it covered.
  
Changing vertex buffers? Blam, your performance is garbage.
  
Starting and stopping renderpasses? Take your entire computer and throw it in the dumpster, because that's where your performance just went.
  
## vkoverhead: Mythbusting
The obvious problem with this is that somebody has to actually dig into the `vkoverhead` results for each driver and figure out what can be made better. I'll write another post about this since it's a separate topic.
  
Instead, what I want to do today is use `vkoverhead` to delve into one of the great myths of Vulkan:
  
**Are fast-linked Graphics Pipeline Libraries worse than, equivalent to, or better than [VK_EXT_vertex_input_dynamic_state](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_EXT_vertex_input_dynamic_state.html)?**
  
I say this is one of the great myths because, having spoken to Very Knowledgeable Khronos Insiders as well as Experienced Application Developers, I've been told repeatedly that `VK_EXT_vertex_input_dynamic_state` is just a convenience feature that should not be used or relied upon, as proper use of GPL with fast-linking provides the same functionality and performance with broader adoption. But is this really true?

Well, now that the tools exist, it's possible to say definitively that this is wishful thinking that does not reflect reality.
  
