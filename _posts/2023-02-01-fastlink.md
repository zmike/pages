---
published: false
---
## Fastlinking: This Is Your Howto

I previously wrote a post talking about some optimization work that's been done with RADV to improve fast-link performance. As promised, that wasn't the end of the story. Today's post will be a bit different, however, as I'll be assuming all my graphics experts in the audience are already well-versed in all the topics I'm covering.

Also I'm assuming you're all driver developers interested in improving your GPL fastlink performance.

The one exception is that today I'll be using a specific definition for *fast* when it comes to fast-linking: to be *fast*, a driver should be able to fast-link in **under 0.01ms**. In an extremely CPU-intensive application, this should allow for even the explodiest of pipeline explosions (100+ fast-links in a single frame) to avoid any sort of hitching/stuttering.

## Testing
To begin evaluating fastlink performance, it's important to have test cases. Benchmarks. The sort that can be easily run, easily profiled, easily understood.

[vkoverhead](https://github.com/zmike/vkoverhead) is the premiere tool for evaluating CPU overhead in Vulkan drivers, and thanks to Valve, it now has support for GPL fastlink based on real pipelines used in Dota2.

For anyone interested in running these cases, it's as simple as building and then running:

`./vkoverhead -start 135`

These benchmark cases will call `vkCreateGraphicsPipelines` in a tight loop to perform a fast-link on GPL-created pipeline libraries, fast-linking thousands of times per second for easy profiling. The number of iterations per second, in thousands, is then printed.

vkoverhead works with any Vulkan driver on any platform (including Windows!), which means it's possible to use it to profile and optimize any driver.

## Optimization
vkoverhead currently has two cases for GPL fastlink. As they are both extracted directly from Dota2, they have a number of properties in common:
* similar descriptor layouts/requirements
* same composition of libraries (all four GPL stages created separately)

Each case tests the following:
* `depthonly` is a pipeline containing only a vertex shader, forcing the driver to use its own fragment shader
* `slow` is a pipeline that happens to be slow to create on many drivers

Various tools are available on different platforms for profiling, and I'm not going to go into details there. What I'm going to do instead is look into strategies for optimizing drivers. Strategies that I (and others) have employed in real drivers. Strategies that you, if you aren't shipping a fast-linking implementation of GPL, might be interested in implementing.

## First Strategy: Move NO-OP Fragment Shader To Device
The `depthonly` case explicitly tests whether drivers are creating a new fragment shader for every pipeline that lacks one. Drivers *should not* do this.

Instead, create a single fragment shader on the device object and reuse it:
* [RADV](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21042)
* [Lavapipe]()

In addition to being significantly faster, this also saves some memory.

## Second Strategy: Avoid Copying Shader IR
Regular, optimized pipeline creation typically involves running optimization passes across the shader binaries, possibly even the entire pipeline, to ensure that various cross-stage speedups can be found. Many drivers copy the internal shader IR in the course of this to handle shader variants.

Don't copy shader IR when trying to fast-link a pipeline.

Copying IR is very expensive, especially in larger shaders. Instead, either precompile unoptimized shader binaries in their corresponding GPL stage or refcount IR structures that must exist during execution. Examples:
* [RADV recently switched to using precompiled, unoptimized binaries](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21008)
* [Lavapipe now refcounts NIR structs]()

## Third Strategy: Avoid Compiling Shaders
This one seems obvious, but it has to be stated.

**Do not compile shaders when attempting to achieve fast-link speed.**

If you are compiling shaders, this is a very easy optimization point.

## Fourth Strategy: Avoid Caching Fast-link Pipelines
There's no point caching a fast-linked pipeline. The amount of time saved by retrieving a cached pipeline should be outweighed by the amount of time required to:
* compute a key/hash for a given pipeline
* access the cache

I say *should* because ideally a driver should be fast enough to combine a GPL pipeline so fast that even a cache hit is only comparable performance, if not slower outright. Skip all aspects of caching for these pipelines.

* [RADV recently optimized this away](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21009)

## Fifth Strategy: Misc Profiling
If a driver is slow after checking for the above items, it's time to try profiling. It's surprising what slowdowns drivers will hit. Some examples:
* [RADV dynamic state initialization had a big memset](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/20960)
* [another big RADV memset](https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/20947)
* [Lavapipe deferred compilation]()*\
Lavapipe is special because it is both a CPU-based driver using LLVM, meaning the time spent out of LLVM will never exceed the time spent inside LLVM, and it executes its command buffers in a thread. Thus, it can "cheat" by deferring the final compile of its shaders until pipeline bind time.

## A Mystery Solved
In my previous post, I alluded to a driver that was shipping a GPL implementation that advertised fast-link but wasn't actually fast. I saw a lot of guesses. Nobody got it right.



anv
```
$ ./vkoverhead -start 135 -duration 5
vkoverhead running on Intel(R) Iris(R) Plus Graphics (ICL GT2):
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      384,          100.0%
 136, misc_compile_fastlink_slow,                           276,          100.0%

$ VK_ICD_FILENAMES=/usr/local/share/vulkan/icd.d/lvp_icd.x86_64.json ./vkoverhead -start 135 -duration 5
vkoverhead running on llvmpipe (LLVM 15.0.6, 256 bits):
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      571,          100.0%
 136, misc_compile_fastlink_slow,                           607,          100.0%
```


radv
```
$ VK_ICD_FILENAMES=/usr/share/vulkan/icd.d/nvidia_icd.json ./vkoverhead -start 135 -duration 5
vkoverhead running on NVIDIA GeForce RTX 2070:
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      444,          100.0%
 136, misc_compile_fastlink_slow,                           243,          100.0%
 
$ RADV_PERFTEST=gpl ./vkoverhead -start 135 -duration 5
vkoverhead running on AMD Radeon RX 5700 XT (RADV NAVI10):
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      301,          100.0%
 136, misc_compile_fastlink_slow,                           283,          100.0%

$ VK_ICD_FILENAMES=/usr/local/share/vulkan/icd.d/lvp_icd.x86_64.json ./vkoverhead -start 135 -duration 5
vkoverhead running on llvmpipe (LLVM 15.0.6, 256 bits):                                                                   
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      544,          100.0%
 136, misc_compile_fastlink_slow,                           536,          100.0%
```


tu
```
$ ./vkoverhead -start 135
vkoverhead running on Turnip Adreno (TM) 618:
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                       73,           100.0%
 136, misc_compile_fastlink_slow,                            23,           100.0%

$ VK_ICD_FILENAMES=/usr/local/share/vulkan/icd.d/lvp_icd.aarch64.json ./vkoverhead -start 135
vkoverhead running on llvmpipe (LLVM 14.0.6, 128 bits):
	* misc numbers are reported as thousands of operations per second
	* percentages for misc cases should be ignored
 135, misc_compile_fastlink_depthonly,                      331,          100.0%
 136, misc_compile_fastlink_slow,                           361,          100.0%
```

| Item         | Price | # In stock |
|--------------|:-----:|-----------:|
| Juicy Apples |  1.99 |        739 |
| Bananas      |  1.89 |          6 |
